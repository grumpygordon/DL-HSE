{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "8nnyqcw20owpld0m2l636o",
        "id": "kdnbiWeyTzYe"
      },
      "outputs": [],
      "source": [
        "# %pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# %pip install pandas==1.3.3 pytorch-fid==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "wdvy5kbhnmb230c8g513w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0VHWz8ITzYh",
        "outputId": "8c51dca3-2337-442c-f03c-595236fc65a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111 0.11.1+cu111 0.2.1 1.1.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import pytorch_fid\n",
        "\n",
        "print(torch.__version__, torchvision.__version__, pytorch_fid.__version__, pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "d4c0x78ais8ig1ecxaew2",
        "id": "hzaR5p6PTzYh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seeds(val=23):\n",
        "    torch.manual_seed(val)\n",
        "    np.random.seed(val)\n",
        "    random.seed(val)\n",
        "\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "t5unbkghslm9klk1oasff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDOLkHvqTzYi",
        "outputId": "f9f50d43-e681-450f-ca0d-3b4357459f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-15 19:07:39--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30168306 (29M) [application/x-gzip]\n",
            "Saving to: ‘facades.tar.gz’\n",
            "\n",
            "facades.tar.gz      100%[===================>]  28.77M  3.26MB/s    in 8.1s    \n",
            "\n",
            "2021-12-15 19:07:47 (3.55 MB/s) - ‘facades.tar.gz’ saved [30168306/30168306]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "zajr9gfan7gb1kq1iy54h",
        "id": "RsCgf3moTzYi"
      },
      "outputs": [],
      "source": [
        "!tar -xf facades.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "fy13asubg7wfzjt9ojne3d",
        "id": "m6Jfabq6TzYi",
        "outputId": "3e92400f-914a-452b-d5ec-0094f3bb5bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-04 12:04:25--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/cityscapes.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103441232 (99M) [application/x-gzip]\n",
            "Saving to: ‘cityscapes.tar.gz’\n",
            "\n",
            "cityscapes.tar.gz   100%[===================>]  98.65M   507KB/s    in 4m 32s  \n",
            "\n",
            "2021-12-04 12:08:57 (371 KB/s) - ‘cityscapes.tar.gz’ saved [103441232/103441232]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/cityscapes.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "824iiphpe08qtxvoue0r8",
        "id": "7XsXmdZITzYj"
      },
      "outputs": [],
      "source": [
        "!tar -xf cityscapes.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "h9k7hxo8eo4qixylymm2fk",
        "id": "Fum_dNapTzYj"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def split(X):\n",
        "    # (n, h, 2*w, c)\n",
        "    X = np.transpose(X, (0, 3, 1, 2))\n",
        "    # (n, c, h, 2*w)\n",
        "    X_1 = X[:, :, :, 256:]\n",
        "    X_2 = X[:, :, :, :256]\n",
        "    return np.stack((X_1, X_2), axis=1)\n",
        "    # (n, 2, c, h, 2*w)\n",
        "\n",
        "def load_dataset(name):\n",
        "    X_train = []\n",
        "    X_val = []\n",
        "    X_test = []\n",
        "\n",
        "    for file in sorted(glob.glob(name+'/train/*')):\n",
        "        X_train.append(np.array(Image.open(file)))\n",
        "\n",
        "    for file in sorted(glob.glob(name+'/val/*')):\n",
        "        X_val.append(np.array(Image.open(file)))\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_val = np.array(X_val)\n",
        "\n",
        "    has_test = os.path.exists(name + '/test')\n",
        "    if has_test:\n",
        "        for file in sorted(glob.glob(name+'/test/*')):\n",
        "            X_test.append(np.array(Image.open(file)))\n",
        "        X_test = np.array(X_test)\n",
        "    else:\n",
        "        sz = int(len(X_val) * 0.4)\n",
        "        X_test = X_val[:sz]\n",
        "        X_val = X_val[sz:]\n",
        "        \n",
        "    return split(X_train), split(X_val), split(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "wczrzvs4hqfiyaxnhqlmyk",
        "id": "8i30uimcTzYj"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test = load_dataset('facades')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "i0vvqzkz42n14kai8s83v1",
        "id": "oMUNpkKsTzYk"
      },
      "outputs": [],
      "source": [
        "Image.fromarray(X_train[0][0].transpose((1, 2, 0))).show()\n",
        "Image.fromarray(X_train[0][1].transpose((1, 2, 0))).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "duso52qf1hg3q6gkiz6fhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpSD2qmTTzYk",
        "outputId": "ac1eec62-ab39-4e2d-b5e5-04d6fa940b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 2, 3, 256, 256) (100, 2, 3, 256, 256) (106, 2, 3, 256, 256) uint8\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape, X_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "e8oka0f3ozzxhp9zx5jf",
        "id": "nCQNhTjzTzYk"
      },
      "outputs": [],
      "source": [
        "# adapted from shw2\n",
        "\n",
        "from torchvision import models, transforms\n",
        "import torchvision.transforms.functional_tensor as TF\n",
        "import torchvision.transforms.functional as TR_F\n",
        "\n",
        "@torch.no_grad()\n",
        "def train_transform(X):\n",
        "    X = torch.from_numpy(X.copy())\n",
        "    UP = 286\n",
        "    LOW = 256\n",
        "    Y = torch.zeros(X.shape[0], 2, 3, UP, UP)\n",
        "    for i in range(len(X)):\n",
        "        tr = transforms.Resize(UP)\n",
        "        Y[i][0] = TF.resize(X[i][0], UP)\n",
        "        Y[i][1] = TF.resize(X[i][1], UP)\n",
        "        #done resize(286)\n",
        "        top, left, h, w = transforms.RandomCrop(LOW).get_params(Y[i][0], (LOW, LOW))\n",
        "        X[i][0] = TF.crop(Y[i][0], top, left, h, w)\n",
        "        X[i][1] = TF.crop(Y[i][1], top, left, h, w)\n",
        "        #done randomCrop(256)\n",
        "        if np.random.rand() < 0.5:\n",
        "            X[i][0] = TF.hflip(X[i][0])\n",
        "            X[i][1] = TF.hflip(X[i][1])\n",
        "        \n",
        "    X = TF.convert_image_dtype(X, torch.float32)\n",
        "    X = X * 2 - 1\n",
        "    #[-1;1] range\n",
        "    return X\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_transform(X):\n",
        "    X = torch.from_numpy(X.copy())\n",
        "    X = TF.convert_image_dtype(X, torch.float32)\n",
        "    X = X * 2 - 1\n",
        "    return X\n",
        "\n",
        "#torch (c, h, w) to pil\n",
        "@torch.no_grad()\n",
        "def to_PIL(x):\n",
        "    #[-1;1]\n",
        "    x = (x + 1) / 2\n",
        "    x = TF.convert_image_dtype(x, torch.uint8)\n",
        "    x = TR_F.to_pil_image(x)\n",
        "    return x\n",
        "\n",
        "# accepts numpy, returns torch\n",
        "data_transforms = {\n",
        "    'train': train_transform,\n",
        "    'val': test_transform,\n",
        "    'test': test_transform\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "ku8zv0gr6mpm8j522j2q6",
        "id": "fzscZVsSTzYl"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "# pix2pix https://arxiv.org/pdf/1611.07004.pdf , architecture and optimizer and etc parameters taken from paper\n",
        "# and their github (details to match architecture) https://github.com/phillipi/pix2pix/blob/master/models.lua\n",
        "# Unet adapted (changed a lot) from shw5\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, batch_norm=True, stride=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        mods = [nn.Conv2d(in_ch, out_ch, 4, stride, 1, bias=not batch_norm)]\n",
        "        if batch_norm:\n",
        "            mods.append(nn.InstanceNorm2d(out_ch))\n",
        "        mods.append(nn.LeakyReLU(0.2))\n",
        "        self.lay = nn.Sequential(*mods)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lay(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=False):\n",
        "        super().__init__()\n",
        "\n",
        "        mods = [nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1, bias=False)]\n",
        "        mods.append(nn.InstanceNorm2d(out_ch))\n",
        "        if dropout:\n",
        "            mods.append(nn.Dropout(0.5))\n",
        "        mods.append(nn.ReLU())\n",
        "        self.lay = nn.Sequential(*mods)\n",
        "\n",
        "\n",
        "    def forward(self, x, old_x):\n",
        "        # (batch, c, h, w)\n",
        "        if old_x is not None: # not None\n",
        "            x = torch.cat((x, old_x), dim=1)\n",
        "        x = self.lay(x)\n",
        "        return x\n",
        "\n",
        "    \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(UNet, self).__init__()\n",
        "        self.down_blocks = []\n",
        "        self.up_blocks = []\n",
        "        \n",
        "        self.down_blocks = [ #3x256x256\n",
        "            DownBlock(3, 64, batch_norm=False), #64x128x128\n",
        "            DownBlock(64, 128), #128x64x64\n",
        "            DownBlock(128, 256), #256x32x32\n",
        "            DownBlock(256, 512), #512x16x16\n",
        "            DownBlock(512, 512), #512x8x8\n",
        "            DownBlock(512, 512), #512x4x4\n",
        "            DownBlock(512, 512), #512x2x2\n",
        "            DownBlock(512, 512, batch_norm=False), #512x1x1\n",
        "        ]\n",
        "        \n",
        "        self.up_blocks = [ #3x256x256\n",
        "            UpBlock(512, 512, dropout=True),\n",
        "            UpBlock(1024, 512, dropout=True),\n",
        "            UpBlock(1024, 512, dropout=True),\n",
        "            UpBlock(1024, 512),\n",
        "            UpBlock(1024, 256),\n",
        "            UpBlock(512, 128),\n",
        "            UpBlock(256, 64),\n",
        "            \n",
        "        ]\n",
        "        self.last_conv = nn.ConvTranspose2d(128, 3, 4, 2, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
        "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        res = []\n",
        "        for i in range(len(self.down_blocks)):\n",
        "            x = self.down_blocks[i](x)\n",
        "            res.append(x)\n",
        "        \n",
        "        res = list(reversed(res[:-1]))\n",
        "        \n",
        "        x = self.up_blocks[0](x, None)\n",
        "        for i in range(1, len(self.up_blocks)):\n",
        "            x = self.up_blocks[i](x, res[i - 1])\n",
        "        \n",
        "        x = self.last_conv(torch.cat((x, res[-1]), dim=1))\n",
        "        x = self.tanh(x)\n",
        "        \n",
        "        return x  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "plfu3hyje9hbqtqwkujbkp",
        "id": "Mm6iszcuTzYl"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, use_input):\n",
        "        super().__init__()\n",
        "        self.use_input = use_input\n",
        "        if use_input:\n",
        "            in_ch = 6\n",
        "        else:\n",
        "            in_ch = 3\n",
        "        #in_ch is 3 or 6, depending on whether we concat input to output\n",
        "        self.blocks = nn.Sequential( #in_chx256x256\n",
        "            DownBlock(in_ch, 64, batch_norm=False), #64x128x128\n",
        "            DownBlock(64, 128), #128x64x64\n",
        "            DownBlock(128, 256), #256x32x32\n",
        "            DownBlock(256, 512, stride=1), #512x34x34\n",
        "            nn.Conv2d(512, 1, 4, 1, 1), #1x30x30\n",
        "        )\n",
        "    \n",
        "    def forward(self, x_in, x):\n",
        "        if self.use_input:\n",
        "            x = torch.cat((x, x_in), dim=1)\n",
        "        \n",
        "        return self.blocks(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "rm1sl35xc1qel1w2f6iwuu",
        "id": "P0CTnZ5rTzYm"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def iterate_minibatches(X, batchsize, mode, todel, shuffle):\n",
        "    \n",
        "    if todel != 1:\n",
        "        X = X[:len(X) // todel]\n",
        "\n",
        "    X = data_transforms[mode](X).numpy()\n",
        "    \n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(X))\n",
        "    \n",
        "    for start_idx in range(0, len(X), batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = np.array(range(start_idx, min(len(X), start_idx + batchsize)))\n",
        "\n",
        "        inp = torch.from_numpy(X[excerpt])\n",
        "        yield inp[:, 0], inp[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "fbb1ylx5lfinxmy19172o",
        "id": "TDHuSngLTzYm"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model_g, model_d, opt_g, opt_d, DEVICE, df_frac, batch_size, use_disc, use_l1):\n",
        "    model_g.train()\n",
        "    \n",
        "    if use_disc:\n",
        "        model_d.train()\n",
        "    \n",
        "    total_loss_g = 0.0\n",
        "    total_loss_d = 0.0\n",
        "\n",
        "    cnter = 0\n",
        "    \n",
        "    for src, tgt in iterate_minibatches(X_train, batch_size, 'train', df_frac, True):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        output = model_g(src)\n",
        "        \n",
        "        #discriminator loss\n",
        "        if use_disc:\n",
        "            out_copy = output.clone().detach()\n",
        "            disc_tgt = model_d(src, tgt)\n",
        "            disc_output = model_d(src, out_copy)\n",
        "            loss_d = F.binary_cross_entropy_with_logits(disc_output, torch.zeros_like(disc_output)) + \\\n",
        "                     F.binary_cross_entropy_with_logits(disc_tgt, torch.ones_like(disc_tgt))\n",
        "            loss_d = loss_d / 2\n",
        "\n",
        "            total_loss_d += loss_d.item()\n",
        "            \n",
        "            opt_d.zero_grad()\n",
        "            loss_d.backward()\n",
        "            opt_d.step()\n",
        "\n",
        "        #generator loss\n",
        "\n",
        "        l1_loss = 100 * F.l1_loss(output, tgt)\n",
        "\n",
        "        loss_g = torch.tensor(0.0).to(DEVICE)\n",
        "\n",
        "        if use_l1:\n",
        "            loss_g = loss_g + l1_loss\n",
        "\n",
        "        if use_disc:\n",
        "            disc_output = model_d(src, output)\n",
        "            loss_g = loss_g + F.binary_cross_entropy_with_logits(disc_output, torch.ones_like(disc_output))\n",
        "        \n",
        "        total_loss_g += loss_g.item()\n",
        "        \n",
        "        opt_g.zero_grad()\n",
        "        loss_g.backward()\n",
        "        opt_g.step()\n",
        "\n",
        "        cnter += 1\n",
        "    \n",
        "    return total_loss_g / cnter, total_loss_d / cnter\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model_g, model_d, DEVICE, df_frac, batch_size, use_disc, use_l1):\n",
        "    #intentional\n",
        "    model_g.train()\n",
        "    \n",
        "    if use_disc:\n",
        "        model_d.train()\n",
        "    \n",
        "    total_loss_g = 0.0\n",
        "    total_loss_d = 0.0\n",
        "\n",
        "    cnter = 0\n",
        "    \n",
        "    for src, tgt in iterate_minibatches(X_val, batch_size, 'train', df_frac, False):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        output = model_g(src)\n",
        "\n",
        "        l1_loss = 100 * F.l1_loss(output, tgt)\n",
        "        \n",
        "        loss_g = torch.tensor(0.0).to(DEVICE)\n",
        "        loss_d = torch.tensor(0.0).to(DEVICE)\n",
        "        \n",
        "        if use_l1:\n",
        "            loss_g = loss_g + l1_loss\n",
        "\n",
        "        if use_disc:            \n",
        "            disc_tgt = model_d(src, tgt)\n",
        "            disc_output = model_d(src, output)\n",
        "            loss_g = loss_g + F.binary_cross_entropy_with_logits(disc_output, torch.ones_like(disc_output))\n",
        "            loss_d = F.binary_cross_entropy_with_logits(disc_output, torch.zeros_like(disc_output)) + \\\n",
        "                     F.binary_cross_entropy_with_logits(disc_tgt, torch.ones_like(disc_tgt))\n",
        "            loss_d = loss_d / 2\n",
        "        \n",
        "        total_loss_g += loss_g.item()\n",
        "        total_loss_d += loss_d.item()\n",
        "        \n",
        "        cnter += 1\n",
        "    \n",
        "    return total_loss_g / cnter, total_loss_d / cnter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "mo8sx3bx1mrdhups3vbx2f",
        "id": "ow1HZWaRTzYn"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def clear_folder(folder):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    files = glob.glob(folder+'/*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "pf242nlmg4fffzs9cpmbo",
        "id": "MaFkYiCWTzYn"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def save_to_folder(dset_name, X_name):\n",
        "    assert dset_name in {'facades', 'cityscapes'}\n",
        "    if X_name == 'val':\n",
        "        X = X_val\n",
        "    elif X_name == 'train':\n",
        "        X = X_train\n",
        "    else:\n",
        "        assert X_name == 'test'\n",
        "        X = X_test\n",
        "    folder = dset_name + '/fid/' + X_name + '_tgt/'\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    files = glob.glob(folder+'*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    cnt = 0\n",
        "    for src, tgt in iterate_minibatches(X, 1, 'test', 1, False):\n",
        "        x = to_PIL(tgt[0])\n",
        "        cnt += 1\n",
        "        x.save(folder + str(cnt) + '.jpg')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "ro4w68deu5pdxvdovs8fjk",
        "id": "8kzGZylCTzYn"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def save_src_to_folder(dset_name, X_name):\n",
        "    assert dset_name in {'facades', 'cityscapes'}\n",
        "    if X_name == 'val':\n",
        "        X = X_val\n",
        "    elif X_name == 'train':\n",
        "        X = X_train\n",
        "    else:\n",
        "        assert X_name == 'test'\n",
        "        X = X_test\n",
        "    folder = dset_name + '/fid/' + X_name + '_src/'\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    files = glob.glob(folder+'*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    cnt = 0\n",
        "    for src, tgt in iterate_minibatches(X, 1, 'test', 1, False):\n",
        "        x = to_PIL(src[0])\n",
        "        cnt += 1\n",
        "        x.save(folder + str(cnt) + '.jpg')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "11iql72k1drpbi8ipkux62r",
        "id": "-9_FJVZvTzYo"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def calculate_fid(dset_name, X_name, model, DEVICE='cuda', filename=None):\n",
        "    import pytorch_fid.fid_score\n",
        "    assert dset_name in {'facades', 'cityscapes'}\n",
        "    if X_name == 'val':\n",
        "        X = X_val\n",
        "    elif X_name == 'train':\n",
        "        X = X_train\n",
        "    else:\n",
        "        assert X_name == 'test'\n",
        "        X = X_test\n",
        "    tgt_folder = dset_name + '/fid/' + X_name + '_tgt/'\n",
        "    out_folder = dset_name + '/fid/' + X_name + '_out/'\n",
        "    os.makedirs(out_folder, exist_ok=True)\n",
        "    cnt = 0\n",
        "    for src, tgt in iterate_minibatches(X, 1, 'test', 1, False):\n",
        "        src = src.to(DEVICE)\n",
        "        output = model(src)\n",
        "        x = to_PIL(output[0].cpu())\n",
        "        if cnt == 0:\n",
        "            x.show()\n",
        "            if filename is not None:\n",
        "                fold = dset_name + '/fid/' + X_name + '_sample/'\n",
        "                os.makedirs(fold, exist_ok=True)\n",
        "                x.save(fold + filename + '.jpg')\n",
        "        cnt += 1\n",
        "        x.save(out_folder + str(cnt) + '.jpg')\n",
        "\n",
        "    fid = pytorch_fid.fid_score.calculate_fid_given_paths([tgt_folder, out_folder], 50, 'cuda', 2048, 8)\n",
        "    return fid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "o1iidurjjiklbutlkmz05a",
        "id": "zn8CnwbKTzYo"
      },
      "outputs": [],
      "source": [
        "save_to_folder('facades', 'train')\n",
        "save_to_folder('facades', 'val')\n",
        "save_to_folder('facades', 'test')\n",
        "save_src_to_folder('facades', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "1bp7tk7zu3vgnt7gto9iit",
        "id": "3_tHZrEqTzYo"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "best_model_wts_g = None\n",
        "best_model_wts_d = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "icyectt3x8dlohvgxbbt4d",
        "id": "NFN1dzN2TzYo"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def train(num_epochs, model_g, model_d, opt_g, opt_d, scheduler, DEVICE, df_frac, batch_size, onlytest, use_disc, use_l1, dset_name):\n",
        "    start_time = time.time()\n",
        "\n",
        "    global best_model_wts_g\n",
        "    global best_model_wts_d\n",
        "    best_model_wts_g = copy.deepcopy(model_g.state_dict())\n",
        "    best_model_wts_d = copy.deepcopy(model_d.state_dict())\n",
        "    best_model_epoch = -1\n",
        "    best_fid = 1e9\n",
        "\n",
        "    lsttt = ['train', 'val']\n",
        "    if onlytest:\n",
        "        lsttt = lsttt[1:]\n",
        "    \n",
        "    train_loss_g_log = []\n",
        "    val_loss_g_log = []\n",
        "    train_loss_d_log = []\n",
        "    val_loss_d_log = []\n",
        "    train_fid_log = []\n",
        "    val_fid_log = []\n",
        "    xs_fid_log = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        BLOCK = 10\n",
        "        \n",
        "        if epoch % BLOCK == 0:\n",
        "            clear_output()\n",
        "        print('epoch', epoch, 'out of', num_epochs)\n",
        "        \n",
        "        for phase in lsttt:\n",
        "            cur_time = time.time()\n",
        "            \n",
        "            print('doing phase', phase)\n",
        "            \n",
        "            if phase == 'train':\n",
        "                loss_g, loss_d = train_epoch(model_g, model_d, opt_g, opt_d, DEVICE, df_frac, batch_size, use_disc, use_l1)\n",
        "                train_loss_g_log.append(loss_g)\n",
        "                train_loss_d_log.append(loss_d)\n",
        "            else:\n",
        "                loss_g, loss_d = evaluate(model_g, model_d, DEVICE, df_frac, batch_size, use_disc, use_l1)\n",
        "                val_loss_g_log.append(loss_g)\n",
        "                val_loss_d_log.append(loss_d)\n",
        "\n",
        "            \n",
        "            print('Generator loss is', loss_g)\n",
        "            print('Discriminator loss is', loss_d)\n",
        "            tt = time.time() - cur_time\n",
        "\n",
        "            if epoch % BLOCK == 0 or epoch + 1 == num_epochs:\n",
        "                sample_filename = None\n",
        "                if epoch % 50 == 0 or epoch + 1 == num_epochs:\n",
        "                    sample_filename = 'epoch_' + str(epoch)\n",
        "                if phase == 'train':\n",
        "                    train_fid = calculate_fid(dset_name, 'train', model_g, DEVICE, sample_filename)\n",
        "                    train_fid_log.append(train_fid)\n",
        "                    print('FID is', train_fid)\n",
        "                else:\n",
        "                    val_fid = calculate_fid(dset_name, 'val', model_g, DEVICE, sample_filename)\n",
        "                    val_fid_log.append(val_fid)\n",
        "                    xs_fid_log.append(epoch)\n",
        "                    print('FID is', val_fid)\n",
        "                    \n",
        "                    if best_fid > val_fid:\n",
        "                        best_fid = val_fid\n",
        "                        best_model_wts_g = copy.deepcopy(model_g.state_dict())\n",
        "                        best_model_wts_d = copy.deepcopy(model_d.state_dict())\n",
        "                        best_model_epoch = epoch\n",
        "                        print('made improvement', best_fid)\n",
        "            \n",
        "                if phase == 'val':\n",
        "                    tt = time.time() - start_time\n",
        "                    print('total elapsed time {:.0f}m {:.0f}s'.format(tt // 60, tt % 60))\n",
        "    \n",
        "    print('')\n",
        "    print('best fid is', best_fid)\n",
        "    print('got such fid at epoch', best_model_epoch)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "3v7z02gz6koopa545lzwe",
        "id": "iGsB3PKdTzYp"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "\n",
        "model_g = UNet()\n",
        "model_d = Discriminator(True)\n",
        "\n",
        "for p in model_g.parameters():\n",
        "    nn.init.normal_(p, 0, 0.02)\n",
        "for p in model_d.parameters():\n",
        "    nn.init.normal_(p, 0, 0.02)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_g = model_g.to(DEVICE)\n",
        "model_d = model_d.to(DEVICE)\n",
        "\n",
        "\n",
        "opt_g = torch.optim.Adam(model_g.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_d = torch.optim.Adam(model_d.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "train(200, model_g, model_d, opt_g, opt_d, None, DEVICE, 1, 1, False, use_disc=True, use_l1=True, dset_name='facades')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!g1.1\n",
        "calculate_fid('facades', 'test', model_g, DEVICE, None)"
      ],
      "metadata": {
        "id": "O85ggrf8e-xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "nv0iucvucho8m9szfcrd1j",
        "id": "yQ79ippOTzYp"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "examples = data_transforms['test'](X_test[-3:])\n",
        "results = model_g(examples[:, 0].cuda()).cpu()\n",
        "for i in range(3):\n",
        "    to_PIL(results[i]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "d7fbb3sskf8aoaoonozt9",
        "id": "1UnRdJH6TzYq"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "model_facades_g = model_g.state_dict()\n",
        "model_facades_d = model_d.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "iql7d9vpvc5jdr8exhrtr",
        "id": "yMOaaNOWTzYq"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test = load_dataset('cityscapes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "tjv3oo7yudbzeh50gekvd",
        "id": "Tfys3-rPTzYq"
      },
      "outputs": [],
      "source": [
        "Image.fromarray(X_val[0][0].transpose((1, 2, 0))).show()\n",
        "Image.fromarray(X_val[0][1].transpose((1, 2, 0))).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "lx0jay0g6peedugeh7bvkw",
        "id": "QTnS0V3sTzYq"
      },
      "outputs": [],
      "source": [
        "save_to_folder('cityscapes', 'train')\n",
        "save_to_folder('cityscapes', 'val')\n",
        "save_to_folder('cityscapes', 'test')\n",
        "save_src_to_folder('cityscapes', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "a8v5jvckimsnh31efvvn4",
        "id": "-FMKeyMPTzYr"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "\n",
        "model_g = UNet()\n",
        "model_d = Discriminator(True)\n",
        "\n",
        "for p in model_g.parameters():\n",
        "    nn.init.normal_(p, 0, 0.02)\n",
        "for p in model_d.parameters():\n",
        "    nn.init.normal_(p, 0, 0.02)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_g = model_g.to(DEVICE)\n",
        "model_d = model_d.to(DEVICE)\n",
        "\n",
        "opt_g = torch.optim.Adam(model_g.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_d = torch.optim.Adam(model_d.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "train(200, model_g, model_d, opt_g, opt_d, None, DEVICE, 1, 1, False, use_disc=True, use_l1=True, dset_name='cityscapes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "ap059h8m2qcozlhwi8bpjq",
        "id": "6vZx8n2OTzYr"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "calculate_fid('cityscapes', 'test', model_g, DEVICE, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "2kbx4dh0ivaegx4yizga0j",
        "id": "F2jlUJbkTzYr"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "model_cityscapes_g = model_g.state_dict()\n",
        "model_cityscapes_d = model_d.state_dict()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Yandex DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "notebookId": "b78378de-5163-437f-9da8-c59e7b9945f2",
    "notebookPath": "main.ipynb",
    "ydsNotebookPath": "main.ipynb",
    "colab": {
      "name": "DL_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}